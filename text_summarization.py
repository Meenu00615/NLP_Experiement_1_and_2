# -*- coding: utf-8 -*-
"""Text_summarization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YnX9yQmOklksHX7ym9-f-th7Va2-mB3K
"""

import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Function to preprocess text
def preprocess_text(text):
    # Tokenize text into sentences
    sentences = sent_tokenize(text)

    # Tokenize each sentence into words
    word_tokens = [word_tokenize(sentence) for sentence in sentences]

    # Remove stopwords
    stop_words = set(stopwords.words("english"))
    filtered_sentences = []
    for sentence_tokens in word_tokens:
        filtered_sentence = [word for word in sentence_tokens if word.lower() not in stop_words]
        filtered_sentences.append(filtered_sentence)

    # Flatten the list of words into a single list of all words
    all_words = [word for sentence in filtered_sentences for word in sentence]

    # Convert the list of words back to text
    processed_text = " ".join(all_words)

    return processed_text, sentences, word_tokens

# Read text data from the .txt file
def read_text_from_file(file_path):
    with open(file_path, 'r') as file:
        text = file.read()
    return text

# Example .txt file path
file_path = 'paper.txt'

# Read text from the .txt file
text = read_text_from_file(file_path)

# Preprocess the text
processed_text, sentences, word_tokens = preprocess_text(text)

# Vectorize the preprocessed text
vectorizer = TfidfVectorizer()
vectorized_text = vectorizer.fit_transform([processed_text])

# Calculate cosine similarity for each sentence
sentence_cosine_sim = cosine_similarity(vectorized_text, vectorized_text)

# Calculate cosine similarity for each word
word_vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)
word_vectorized_text = word_vectorizer.fit_transform(word_tokens)
word_cosine_sim = cosine_similarity(word_vectorized_text, word_vectorized_text)

print("Preprocessed text:")
print(processed_text)
print("\nVectorized text:")
print(vectorized_text)
print("\nCosine similarity matrix for each sentence:")
print(sentence_cosine_sim)
print("\nCosine similarity matrix for each word:")
print(word_cosine_sim)