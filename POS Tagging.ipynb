{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implement the concepts of Stemming & Lemmatization\n"
      ],
      "metadata": {
        "id": "ZGqMAIJamlp6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXTBjJn9meX4",
        "outputId": "63ab64d8-b1f9-490d-e786-53fb7e70e4c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " Reliable pose estimation of uncooperative satellites\n",
            "is a key technology for enabling future on-orbit servicing and\n",
            "debris removal missions. The Kelvins Satellite Pose Estimation\n",
            "Challenge aims at evaluating and comparing monocular vision\u0002based approaches and pushing the state-of-the-art on this prob\u0002lem.\n",
            "\n",
            "Stemmed words:\n",
            " ['reliabl', 'pose', 'estim', 'of', 'uncoop', 'satellit', 'is', 'a', 'key', 'technolog', 'for', 'enabl', 'futur', 'on-orbit', 'servic', 'and', 'debri', 'remov', 'mission', '.', 'the', 'kelvin', 'satellit', 'pose', 'estim', 'challeng', 'aim', 'at', 'evalu', 'and', 'compar', 'monocular', 'vision\\x02bas', 'approach', 'and', 'push', 'the', 'state-of-the-art', 'on', 'thi', 'prob\\x02lem', '.']\n",
            "\n",
            "Lemmatized words:\n",
            " ['Reliable', 'pose', 'estimation', 'of', 'uncooperative', 'satellite', 'is', 'a', 'key', 'technology', 'for', 'enabling', 'future', 'on-orbit', 'servicing', 'and', 'debris', 'removal', 'mission', '.', 'The', 'Kelvins', 'Satellite', 'Pose', 'Estimation', 'Challenge', 'aim', 'at', 'evaluating', 'and', 'comparing', 'monocular', 'vision\\x02based', 'approach', 'and', 'pushing', 'the', 'state-of-the-art', 'on', 'this', 'prob\\x02lem', '.']\n"
          ]
        }
      ],
      "source": [
        "#importing the dependencies for stemming and lemmatization\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize  #word_tokenize, sent_tokenize from nltk\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer  #applying PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')     #downloading necessories resources fom nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#declaring functions for stemming and lemmatization\n",
        "def process_text(text):\n",
        "    #tokenize the text into words\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Initialize stemming and lemmatization objects\n",
        "    stemmer = PorterStemmer()\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Perform stemming and lemmatization\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    #returing\n",
        "    return stemmed_words, lemmatized_words\n",
        "\n",
        "#declaring the function to read the txt file by provided by me/user\n",
        "def read_text(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        text = file.read()\n",
        "    return text  #return text\n",
        "\n",
        "def main():\n",
        "    #read text from file's name text.txt\n",
        "    filename = 'text.txt'  # Change to the name of your .txt file\n",
        "    text = read_text(filename)\n",
        "\n",
        "    #perform stemming and lemmatization\n",
        "    stemmed_words, lemmatized_words = process_text(text)\n",
        "\n",
        "    #results\n",
        "    print(\"Original text:\\n\", text)\n",
        "    print(\"\\nStemmed words:\\n\", stemmed_words)\n",
        "    print(\"\\nLemmatized words:\\n\", lemmatized_words)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f0qsi0yL03fl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
